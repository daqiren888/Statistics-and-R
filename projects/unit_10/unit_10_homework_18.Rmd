---
title: "Politics Are Afoot!"
author: 'Da Qi Ren'
#date: "10/21/2020"
output: pdf_document
---

# The Setup 

There is *a lot* of money that is spent in politics in Presidential election years. So far, estimates have the number at about $11,000,000,000 (11 billion USD). For context, in 2019 Twitter's annual revenue was about \$3,500,000,000 (3.5 billion USD). 

# The work 

Install the package, `fec16`. 

```{r}
## install.packages('fec16')
```

This package is a compendium  of spending and results from the 2016 election cycle. In this dataset are 9 different datasets that cover: 

- `candidates`: candidate attributes, like their name, a unique id of the candidate, the election year under consideration, the office they're running for, etc. 
- `results_house`: race attributes, like the name of the candidates running in the election, a unique id of the candidate, the number of `general_votes` garnered by each candidate, and other information. 
- `campaigns`: financial information for each house & senate campaign. This includes a unique candidate id, the total receipts (how much came in the doors), and total disbursements (the total spent by the campaign), the total contributed by party central committees, and other information. 

# Your task 

Describe the relationship between spending on a candidate's behalf and the votes they receive.

# Your work 

- We want to keep this work *relatively* constrained, which is why we're providing you with data through the `fec16` package. It is possible to gather all the information from current FEC reports, but it would require you to make a series of API calls that would pull us away from the core modeling tasks that we want you to focus on instead. 
- Throughout this assignment, limit yourself to functions that are  within the `tidyverse` family of packages: `dplyr`, `ggplot`, `patchwork`, and `magrittr` for wrangling and exploration and `base`, `stats`, `sandwich` and `lmtest` for modeling and testing. You do not *have* to use these packages; but try to limit yourself to using only these. 

```{r load packages, message=FALSE, include=FALSE}
library(tidyverse)
library(magrittr)
library(ggplot2)
library(patchwork)
library(sandwich)
library(lmtest)
library(fec16)
library(scales) 
library(compare)
library(dplyr)
library(gvlma)
library(caret)
library(e1071)
library(car)
library(ggpubr)
library(cowplot)
library(gridExtra)

theme_set(theme_minimal())
knitr::opts_chunk$set(dpi = 300)
```

```{r load data, include=FALSE}
candidates    <- fec16::candidates
results_house <- fec16::results_house
campaigns     <- fec16::campaigns
```


\newpage



## 1. What does the distribution of votes and of spending look like? 

1. (3 points) In separate histograms, show both the distribution of votes (measured in \
`results_house$general_percent` for now) and spending (measured in `ttl_disb`).  Use a log transform if appropriate for each visualization.  How would you describe what you see in these two plots?

**ANSWER:**  

  From my observation, the data `general_percent` and `ttl_disb` have the following problems:  

  - The original data of the 2 variables are not on the same scale (Fig. A-B) .
  - Has skewness problems because the curve appears distorted and skewed to the left in a statistical distribution. 
  - The data are not centered. 

  At this stage, based on my finding, we need to perform data transforming including scaling, centering and skewness corrections. 

  I will perform Log transformation first, because log transform makes the data as “normal” as possible so that the statistical analysis results from this data become more valid,  the log transformation reduces or removes the skewness of our original data. In detail I choose natural logarithm here for the purposes of linear modeling , i.e.,  using Log transformation replaces each variable x with a log(x). The results are shown in Fig. C-D, repectivelay. In C and D, after the transfermation, the vurves approcimately follows normal distribution, the graph appears symmetry,  there are about as many data values on the left side of the median as on the right side. 

  I will do other data transformations later in the following questions.  Data transformation can make our model working efficiently: distance based models perform well when data is pre-processed and transformed; having all features scaled it speeds up the model; better accuracy and more generalized model. 

\


```{r include=FALSE}
write.csv(candidates, "c.csv")
write.csv(results_house, "r.csv")
write.csv(campaigns, "ca.csv")

summary(candidates)
summary(results_house)
summary(campaigns)
```



```{r echo=FALSE, message=FALSE, warning=FALSE}

p1<-ggplot(results_house, aes(x= general_votes)) +
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")
 
p2<-ggplot(campaigns, aes(x= ttl_disb)) +
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")

p3<-ggplot(results_house,aes(x= general_votes)) +
  geom_density() +
  scale_x_continuous(breaks = trans_breaks("log", function(x) 10^x), trans = scales::log_trans())+
  geom_histogram(aes(y=..density..), colour="black", fill="white")+
  geom_density(alpha=.2, fill="#FF6666")+
  labs(x = "log(general_votes)")

p4<-ggplot(campaigns, aes(x= ttl_disb)) +
  geom_density() +
  scale_x_continuous(breaks = trans_breaks("log", function(x) 10^x), trans = scales::log_trans())+
  geom_histogram(aes(y=..density..), colour="black", fill="white")+
  geom_density(alpha=.2, fill="#FF6666")+
  labs(x = "log(ttl_disb)")


ggarrange(p1, p2, p3, p4, labels = c("A", "B", "C", "D"), ncol = 2, nrow = 2)

```



\newpage

## 2. Exploring the relationship between spending and votes. 

2. (3 points) Create a new dataframe by joining `results_house` and `campaigns` using the `inner_join` function from `dplyr`. (We use the format `package::function` -- so `dplyr::inner_join`.) 

**ANSWER:**

  Done the creation of new dataframe by joining `results_house` and `campaigns` using the `inner_join` function from `dplyr`. The new data frame is named "d1". A discription of "d1" is as the follows: 


```{r}
 
d1 <- dplyr::inner_join(results_house, campaigns, by = NULL)
nrow(d1)
summary(d1)

```



\newpage


3. (3 points) Produce a scatter plot of `general_votes` on the y-axis and `ttl_disb` on the x-axis. What do you observe about the shape of the joint distribution? 


**ANSWER:** 

  The scatter plot of `general_votes` on the y-axis and `ttl_disb` on the x-axis is shown below Fig.E. I also made  a scatter plot  using y = log(general_votes) and x=  log(ttl_disb), as shown in Fig.F. 

  In general, a x-y scatter graph displays and compares values to show the numerical distribution of variables in a rectangular coordinate system. A two-dimensional scatter chart can show the data analysis of two variables to provide the relationship and correlation between the two. Scatter plots can provide three types of
key information: 

  - Whether there is a quantitative correlation trend between variables; 
  - If there is a correlation trend, is it linear or non-linear; 
  - Observe whether there are outliers and analyze The influence of these outliers on the modeling analysis.

  However, I couldn't find obvious correlation between variables since most of them look randomly distributed on the scatter plot. If there is a certain correlation, then most of the data points will be relatively dense and present in a certain trend, however I cannot figure it out it by simple observation. 

  By observing the distribution of data points on the scatter plot, I found there are some outliers.
 
\ 
 

```{r echo=FALSE, message=FALSE, warning=FALSE}

p5 <- ggplot(d1, aes(y=general_votes, x=ttl_disb)) +
  geom_point(size=2, shape=23)+
  geom_smooth(method=lm)

p6 <- ggplot(d1, aes(x=log(ttl_disb), y=log(general_votes))) +
  geom_point(size=2, shape=23)+
  geom_smooth(method=lm)

ggarrange(p5, p6, labels = c("E", "F"), ncol = 2, nrow = 2)

```

\newpage


4. (3 points) Create a new variable to indicate whether each individual is a "Democrat", "Republican" or "Other Party". 
  - Here's an example of how you might use `mutate` and `case_when` together to create a variable. 

```
starwars %>%
  select(name:mass, gender, species) %>%
  mutate(
  type = case_when(
    height > 200 | mass > 200 ~ "large",
    species == "Droid"        ~ "robot",
    TRUE                      ~ "other"
    )
  )
```

Once you've produced the new variable, plot your scatter plot again, but this time adding an argument into the `aes()` function that colors the points by party membership.  What do you observe about the distribution of all three variables?



**ANSWER:**


  The new variable has been produced, the new data frame is named "d2", a discription is as the follows : 


```{r echo=FALSE, message=FALSE, warning=FALSE}
d2<-d1 %>%
  dplyr::select(party, general_votes, ttl_disb) %>%
  na.omit() %>%
    mutate(
    can_party = case_when(
      party=="REP" ~ "REP",
      party=="DEM" ~ "DEM",
      TRUE ~ "Other"
    )
  )

d2<-d2 %>% dplyr::select(can_party, general_votes, ttl_disb)

summary(d2)

 
```


 


```{r echo=FALSE, message=FALSE, warning=FALSE}


p0 <- ggplot(d2, aes(y = general_votes, x=ttl_disb, color=can_party)) +
  geom_smooth(method=lm)+
  geom_point(size=2, shape=23)


p1<-ggplot(d2, aes(x=general_votes, y=ttl_disb, color=can_party)) + 
  geom_point() + 
  scale_color_manual(values = c("red", "blue", "green")) + 
  theme(legend.position=c(1,1), legend.justification=c(1,1))


p2<-ggplot(d2, aes(x=general_votes, fill=can_party)) + 
  geom_density(alpha=.5) + 
  scale_fill_manual(values =  c("red", "blue", "green")) + 
  theme(legend.position=c(1,1), legend.justification=c(1,1))

# Marginal density plot of y (right panel)
p3<-ggplot(d2, aes(x=ttl_disb, fill=can_party)) + 
  geom_density(alpha=.5) + 
  scale_fill_manual(values =  c("red", "blue", "green")) + 
  theme(legend.position = "none")

p4<-ggplot(d2, aes(x=can_party, fill=can_party)) + 
  geom_density(alpha=.5) + 
  scale_fill_manual(values =  c("red", "blue", "green")) + 
  theme(legend.position = "none")


ggarrange(p1, p2, p3, p4, labels = c("G", "H", "I", "J" ), ncol = 2, nrow =2)

```


  From my observation in Fig H-J, the variable general_percent,ttl_disb and can_party have the following properties:
  
  - The distribution of each of the three variables (i.e. can_party, ttl_disp, general_vote)  are a combination of 3 different curves that are approximately following  normal  distributions. 
  - For each variable, the 3 curves in different color clustered by the 3  (i.e. DEM , REP, and Other)  parties.
  - Among the total 9 curves, each of the curves appears symmetry, there are about as many data values on the left side of the median as on the right side.
  - Each of the curves has skewness problems because the curve appears distorted or skewed to the left or right in a statistical distribution.
  - The data in each curve are not centered.

  At this stage, based on my finding, the following decisions are made: 
  
  - A linear model can be created and fit the relationship between the general_votes and ttl_disb and can_party. 
  - Detailed analysis and pre-processing need to be done to the data using maths.
  - further data transformations have to be performed.
  
  Next, I will do the data pre-processing and model creation.
  
   

\newpage

# Produce a Descriptive Model 

5. (5 Points) Given your observations, produce a linear model that you think does a good job at describing the relationship between candidate spending and votes they receive. You should decide what transformation to apply to spending (if any), what transformation to apply to votes (if any) and also how to include the party affiliation.


```{r echo=TRUE, message=FALSE, warning=FALSE}
d5<-d2 %>%
  dplyr::select(can_party, general_votes, ttl_disb) %>%
  na.omit() %>%
    mutate(
    can_party = case_when(
      can_party=="REP" ~ 0,
      can_party=="DEM" ~ 1,
      TRUE ~ 2
    )
  )

d2<-d5 %>% dplyr::select(can_party, general_votes, ttl_disb)

```

 


```{r echo=TRUE, message=FALSE, warning=FALSE}

d2[d2 == -Inf] <- 0

sdat <- d2[, c("general_votes", "ttl_disb", "can_party")]

imp <- preProcess(sdat, method = c("bagImpute"), k = 5)
sdat <- predict(imp, sdat)
transformed <- spatialSign(sdat)
transformed <- as.data.frame(transformed)
par(mfrow = c(1, 2), oma = c(2, 2, 2, 2))
plot(general_votes ~ ttl_disb, data = sdat, col = "blue", main = "Before")
plot(general_votes ~ ttl_disb, data = transformed, col = "blue", main = "After")

d2$novotes<-transformed$"general_votes"
d2$nodisb<-transformed$"ttl_disb"
d2$noparty<-transformed$"can_party"

#d2<-transformed

```

 

 

```{r echo=TRUE, message=FALSE, warning=FALSE}
 
trans <- preProcess(d2, method = c("center", "scale"))
# use predict() function to get the final result
d3 <- predict(trans, d2)
d2$csvotes = d3$general_votes
d2$csdisb = d3$ttl_disb
d2$csparty = d3$can_party
 
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
 
d2$logdisb <- log(d2$ttl_disb)
d2$logvotes <- log(d2$general_votes)
d2$logparty <- log(d2$can_party)
d2 <- na.omit(d2) 
d2[d2 == -Inf] <- 0
 
fit0 <- lm(d2$general_votes ~ d2$ttl_disb  + d2$can_party)
summary(fit0)

fit1 <- lm(d2$csvotes ~ d2$csdisb  + d2$csparty)
summary(fit1)

fit2 <- lm(d2$novotes ~ d2$nodisb  + d2$noparty)
summary(fit2)
 
fit3 <- lm(d2$logvotes ~ d2$logdisb  + d2$logparty)
summary(fit3)
 
fit4 <- lm(d2$general_votes ~ d2$logdisb + d2$can_party)
summary(fit4)

```

\newpage


```{r echo=TRUE, message=FALSE, warning=FALSE}
 
attach(d2)

c1 <- lm(logvotes ~ logdisb + logparty)
summary(c1)

e <- resid(c1)
c2 <- lm(e^2 ~ logdisb + logparty + I(logdisb^2) + I(logparty^2) + I(logdisb*logparty))
R2 <- summary(c2)$r.sq
n <- nrow(c2$model)
m <- ncol(c2$model)
W <- n*R2
P <- 1 - pchisq(W, m - 1)
c3 <- lm(logvotes ~  logdisb + logparty, weights = 1/abs(e))
summary(c3)

```

