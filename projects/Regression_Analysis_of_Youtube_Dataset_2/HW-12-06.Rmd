---
title: "HW week 12"
author: "w203 teaching team"
subtitle: 'w203: Statistics for Data Science'

output:
  pdf_document: default
  html_document: default
---



```{r setup, include=FALSE}


library(tidyverse) 
library(magrittr)
library(knitr)
library(patchwork)
library(ggplot2)
library(ggpubr)
library(rstatix)
library(dplyr)
library(nortest)
library(splitstackshape)
library(haven)
library(nhstplot)
library(gplots)
library(kableExtra)
library(readxl)
library(lmtest)
library(stargazer)
library(readxl)
library(sandwich)    # White standard errors
library(mvoutlier)
library(car)
library(fec16)
library(scales) 
library(compare)
library(gvlma)
library(caret)
library(e1071)
#library(car)
#library(ggpubr)
library(cowplot)
library(gridExtra)


#library(outliners)
knitr::opts_chunk$set(echo = TRUE)
```

## More regression analysis of YouTube dataset

You want to explain how much the quality of a video affects the number of views it receives on social media.  **This is a causal question.**

You will use a dataset created by Cheng, Dale and Liu at Simon Fraser University.  It includes observations about 9618 videos shared on YouTube.  Please see [this link](http://netsg.cs.sfu.ca/youtubedata/) for details about how the data was collected.

You will use the following variables:

- views: the number of views by YouTube users.

- rate: the average rating given by users.

- length: the duration of the video in seconds.



a. Perform a brief exploratory data analysis on the data to discover patterns, outliers, or wrong data entries and summarize your findings.



### ANSWER: 


I firstly imported data from the csv file.


```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

df<-read.csv('videos001.csv')
df <- subset(df, select = c('rate', 'views', 'length'))  

nrow(df)
df <- na.omit(df)
nrow(df)

summary(df)

write.csv(df,'v.csv')

```

```{r}

fit <- lm(df$views ~ df$rate + df$length)
par(mfrow=c(2,2))
plot (fit)

summary(fit)

df <- df[-c(5128),] 
df <- df[-c(5118),] 

fit <- lm(df$views ~ df$rate + df$length)
par(mfrow=c(2,2))
plot (fit)

summary(fit)
car::outlierTest(fit)


df$logviews = log(df$views) 
df$lograte = log(df$rate) 
df$loglength = log(df$length) 

df <- na.omit(df)

row_sub = apply(df, 1, function(row) all(row !=0 ))
df <- df[row_sub,]


write.csv(df,'w.csv')

# 
# car::outlier(df$views)
# 
# 
# outlier_values <- boxplot.stats(df$views)$length
# boxplot(df$views, main="Views", boxwex=0.1)
# mtext(paste("Outliers: ", paste(outlier_values, collapse=", ")), cex=0.6)


```

```{r}


p00<-ggplot(df, aes(x= views)) +
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")
 
p11<-ggplot(df, aes(x= rate)) +
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")

p22<-ggplot(df, aes(x= length)) +
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")

ggarrange(p00, p11, p22, labels = c("G", "H", "I" ), ncol = 2, nrow =2)


p0<-ggplot(df, aes(x= views)) +
  geom_density() +
  scale_x_continuous(breaks = trans_breaks("log", function(x) 10^x), trans = scales::log_trans())+
  geom_histogram(aes(y=..density..), colour="black", fill="white")+
  geom_density(alpha=.2, fill="#FF6666")+
  labs(x = "log(ttl_disb)")


p1<-ggplot(df, aes(x= rate)) +
  geom_density() +
  scale_x_continuous(breaks = trans_breaks("log", function(x) 10^x), trans = scales::log_trans())+
  geom_histogram(aes(y=..density..), colour="black", fill="white")+
  geom_density(alpha=.2, fill="#FF6666")+
  labs(x = "log(ttl_disb)")


p2<-ggplot(df, aes(x= length)) +
  geom_density() +
  scale_x_continuous(breaks = trans_breaks("log", function(x) 10^x), trans = scales::log_trans())+
  geom_histogram(aes(y=..density..), colour="black", fill="white")+
  geom_density(alpha=.2, fill="#FF6666")+
  labs(x = "log(ttl_disb)")



ggarrange(p1, p2, p0, labels = c("G", "H", "I" ), ncol = 2, nrow =2)


```
 



b. Based on your EDA, select an appropriate variable transformation (if any) to apply to each of your three variables.  You will fit a model of the type,
$$ f(\text{views}) = \beta_0 + \beta_1 g(\text{rate})  + \beta_3 h(\text{length})$$ 
Where $f:\mathbb{R}\to\mathbb{R}$, $g:\mathbb{R}\to\mathbb{R}$, $h:\mathbb{R}\to\mathbb{R}$ are sensible transformations.




```{r}


f1 <- lm(df$views ~ df$rate + df$length)

summary(f2)

f2 <- lm(df$logviews ~ df$lograte + df$loglength)

summary(f2)

 

par(mfrow=c(2,2))
plot (f2)

```



c. Using diagnostic plots, background knowledge, and statistical tests, assess all five assumptions of the CLM. When an assumption is violated, state what response you will take.  As part of this process, you should decide what tranformation (if any) to apply to each variable.


```{r}

#model <- lm(mpg~disp+hp+wt+drat, data=mtcars)

#?mtcars

coeftest(f1,vcov=vcovHC(fit))

#4 Zero Conditional Mean/Linear conditional mean
#x11()
plot(f1, which =1)

plot(df$views,f1$residuals)
plot(df$rate,f1$residuals)
plot(df$length,f1$residuals)

#plot.smooth.line(mtcars$drat,model$residuals, f=0.1)

# Variance Inflation Factor
vif(f1)
vif(f1) > 4

#5 Homoskedasticity
#x11()
plot(f1, which = 3)

#6 Normality of Errors
#x11()
plot(f1, which = 2)

# Look at the histogram of residuals
#x11()
hist(f1$residuals, breaks = 20, main = "Residuals from Linear Model Predicting MPG")



# Estimating and testing significance of coeficients
# With robust standard errors
coeftest(f1, vcov = vcovHC)

# Wt summary
summary(f1)

df3<-df[,c("views","rate","length")]

pairs(df3)
cor(df3)

```












```{r}
 

# Leverage (Actual Influence)
# Cooks distance
#x11()
plot(f1, which=5)

# Log transform mpg
m2 <- lm(log(df$views)~df$rate + df$length, data=df) 
#x11()
coeftest(m2,vcovHC)

plot(m2, which=1)

# Log transform Q-Q Plot
#x11()
plot(m2, which=2)

# Log transform heteroskedasticity
#x11()
plot(m2, which=3)

# Log transformed Leverage (Actual Influence)
# Cooks distance
#x11()
plot(m2, which=5)


# Comparing two models
paste('Level-level Model Adjusted R Squared: ', summary(m2)$adj.r.squared)
paste('Log-level Model Adjusted R Squared: ', summary(m2)$adj.r.squared)

# format regression comparison
(se.fit = sqrt(diag(vcovHC(fit))))
(se.m2 = sqrt(diag(vcovHC(m2))))

# We pass the standard errors into stargazer through 
# the se argument.
stargazer(f1, m2, type = "text", omit.stat = "f",
          se = list(se.fit, se.m2),
          star.cutoffs = c(0.05, 0.01, 0.001))




```





